{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinação 1: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "Combinação 2: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "Combinação 3: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "Combinação 4: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "Combinação 5: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "Combinação 6: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "Combinação 7: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "Combinação 8: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "Combinação 9: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "Combinação 10: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Combinação 11: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Combinação 12: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Combinação 13: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Combinação 14: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Combinação 15: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Combinação 16: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "Combinação 17: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Combinação 18: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Combinação 19: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Combinação 20: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Combinação 21: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Combinação 22: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Combinação 23: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Combinação 24: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "Combinação 25: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "Combinação 26: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "Combinação 27: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Combinação 28: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Combinação 29: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Combinação 30: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "Combinação 31: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Combinação 32: neuronios=100, batch_size=20, epochs_options=20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "    neurons  batch_size  epochs          MAE      MAPE         RMSE        R2  \\\n",
      "0       100          20      20  1042.020757  0.024284  1454.537253  0.992267   \n",
      "1       100          20      20  1149.230735  0.024711  1649.731677  0.990053   \n",
      "2       100          20      20  3306.858125  0.076884  3730.559123  0.949134   \n",
      "3       100          20      20   854.950447  0.019280  1292.383875  0.993895   \n",
      "4       100          20      20  2788.800022  0.063234  3257.258001  0.961222   \n",
      "5       100          20      20   831.569060  0.018332  1300.280417  0.993820   \n",
      "6       100          20      20  1487.157086  0.032536  1982.391511  0.985637   \n",
      "7       100          20      20  1111.875797  0.024389  1594.801077  0.990704   \n",
      "8       100          20      20   877.633929  0.018949  1368.294334  0.993157   \n",
      "9       100          20      20  1005.561639  0.021215  1527.003093  0.991478   \n",
      "10      100          20      20   967.430550  0.023038  1333.524324  0.993500   \n",
      "11      100          20      20  1249.711258  0.030771  1602.060944  0.990619   \n",
      "12      100          20      20   821.106120  0.018226  1280.421200  0.994008   \n",
      "13      100          20      20   846.121772  0.019135  1283.863854  0.993976   \n",
      "14      100          20      20   912.080313  0.021467  1309.027747  0.993737   \n",
      "15      100          20      20   812.475338  0.017949  1265.784935  0.994144   \n",
      "16      100          20      20   910.670698  0.019480  1415.343324  0.992678   \n",
      "17      100          20      20   919.378282  0.021480  1333.159086  0.993504   \n",
      "18      100          20      20  1443.053700  0.033412  1856.458112  0.987403   \n",
      "19      100          20      20   869.757356  0.019762  1301.414000  0.993810   \n",
      "20      100          20      20  1711.273934  0.040817  2068.222415  0.984366   \n",
      "21      100          20      20   942.295155  0.022724  1307.255000  0.993754   \n",
      "22      100          20      20   925.666549  0.019795  1431.561590  0.992510   \n",
      "23      100          20      20   863.974524  0.019664  1296.478844  0.993857   \n",
      "24      100          20      20  1980.975913  0.050780  2240.527647  0.981652   \n",
      "25      100          20      20   835.503286  0.018555  1292.149719  0.993898   \n",
      "26      100          20      20   990.281073  0.020858  1514.646041  0.991615   \n",
      "27      100          20      20  1126.413367  0.023957  1637.807211  0.990196   \n",
      "28      100          20      20   925.193781  0.020466  1391.595473  0.992922   \n",
      "29      100          20      20  1030.734914  0.024842  1383.392538  0.993005   \n",
      "30      100          20      20   913.861412  0.019815  1396.369911  0.992873   \n",
      "31      100          20      20   854.066083  0.018678  1331.641571  0.993519   \n",
      "\n",
      "    directional_accuracy_diario  directional_accuracy_semanal  \n",
      "0                         44.72                         94.94  \n",
      "1                         45.08                         93.67  \n",
      "2                         44.36                         93.67  \n",
      "3                         44.54                         93.67  \n",
      "4                         45.62                         94.94  \n",
      "5                         44.72                         92.41  \n",
      "6                         44.90                         94.94  \n",
      "7                         45.26                         93.67  \n",
      "8                         45.26                         93.67  \n",
      "9                         44.90                         93.67  \n",
      "10                        44.36                         94.94  \n",
      "11                        45.26                         93.67  \n",
      "12                        45.26                         93.67  \n",
      "13                        45.62                         93.67  \n",
      "14                        45.26                         93.67  \n",
      "15                        45.97                         93.67  \n",
      "16                        45.44                         94.94  \n",
      "17                        45.26                         93.67  \n",
      "18                        45.08                         93.67  \n",
      "19                        44.54                         93.67  \n",
      "20                        45.62                         93.67  \n",
      "21                        44.90                         94.94  \n",
      "22                        45.80                         94.94  \n",
      "23                        44.54                         92.41  \n",
      "24                        44.90                         94.94  \n",
      "25                        45.08                         93.67  \n",
      "26                        45.97                         93.67  \n",
      "27                        45.80                         94.94  \n",
      "28                        45.26                         94.94  \n",
      "29                        45.80                         94.94  \n",
      "30                        44.19                         93.67  \n",
      "31                        45.26                         93.67  \n",
      "\n",
      "Melhor Modelo: Neurônios=100.0, batch_size=20.0, Epochs=20.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Diretório onde o script está localizado\n",
    "base_diretório = Path(os.getcwd())\n",
    "base_diretório = base_diretório.parent\n",
    "caminho = base_diretório / 'Bases' / 'Bitcoin Historical Data.csv'\n",
    "\n",
    "# Ler arquivo da base\n",
    "acao = pd.read_csv(caminho)\n",
    "\n",
    "# Formatar data\n",
    "acao['Date'] = pd.to_datetime(acao['Date'], format='%m/%d/%Y')\n",
    "\n",
    "# Filtrar a data em que vamos puxar os dados\n",
    "# acao = acao[acao['Date'].dt.year >= 2023]\n",
    "\n",
    "# Converter as colunas referentes a dinheiro para float\n",
    "colunas_dinheiro = ['Price', 'Open', 'High', 'Low']\n",
    "for coluna in colunas_dinheiro:\n",
    "    if acao[coluna].dtype == 'object':  \n",
    "        acao[coluna] = pd.to_numeric(acao[coluna].str.replace(',', ''))\n",
    "\n",
    "# Converter a coluna 'Change %' para float\n",
    "if acao['Change %'].dtype == 'object':  \n",
    "    acao['Change %'] = pd.to_numeric(acao['Change %'].str.replace('%', ''))\n",
    "\n",
    "def converter_vol_para_numero(valor):\n",
    "    if isinstance(valor, str):  # Verifica se o valor é uma string\n",
    "        if 'K' in valor:\n",
    "            return float(valor.replace('K', '').replace(',', '')) * 1000\n",
    "        elif 'M' in valor:\n",
    "            return float(valor.replace('M', '').replace(',', '')) * 1000000\n",
    "        elif 'B' in valor:\n",
    "            return float(valor.replace('B', '').replace(',', '')) * 1000000000\n",
    "        else:\n",
    "            return float(valor.replace(',', ''))\n",
    "    else:\n",
    "        return valor  # Retorna o valor diretamente se já for numérico\n",
    "\n",
    "# Aplicar a função na coluna 'Vol.'\n",
    "acao['Vol.'] = acao['Vol.'].apply(converter_vol_para_numero)\n",
    "\n",
    "# Ordenar data das bases\n",
    "acao = acao.sort_values(by='Date', ascending=True)\n",
    "\n",
    "# Renomear coluna\n",
    "acao = acao.rename(columns={'Vol.': 'Volume'})\n",
    "\n",
    "\n",
    "# Transforma o array de uma dimensão (array([price1, price2, price3, ...])) \n",
    "# em um array 2D com uma coluna (array([[price1], [price2], [price3], ...]))\n",
    "cotacao = acao['Price'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# Separar 80% da base para treinamento\n",
    "tamanho_dados_treinamento = int(len(cotacao) * 0.8)\n",
    "\n",
    "# Escalar os dados entre 0 e 1\n",
    "escalador = MinMaxScaler(feature_range=(0, 1))\n",
    "dados_entre_0_e_1_treinamento = escalador.fit_transform(cotacao[0:tamanho_dados_treinamento, :])\n",
    "dados_entre_0_e_1_teste = escalador.transform(cotacao[tamanho_dados_treinamento:, :])\n",
    "\n",
    "dados_entre_0_e_1 = np.concatenate((dados_entre_0_e_1_treinamento, dados_entre_0_e_1_teste), axis=0)\n",
    "\n",
    "dados_para_treinamento = dados_entre_0_e_1[0:tamanho_dados_treinamento, :]\n",
    "treinamento_x, treinamento_y = [], []\n",
    "\n",
    "for i in range(60, len(dados_para_treinamento)):\n",
    "    treinamento_x.append(dados_para_treinamento[i - 60:i, 0])\n",
    "    treinamento_y.append(dados_para_treinamento[i, 0])\n",
    "\n",
    "# Transformando listas em arrays\n",
    "treinamento_x, treinamento_y = np.array(treinamento_x), np.array(treinamento_y)\n",
    "treinamento_x = treinamento_x.reshape(treinamento_x.shape[0], treinamento_x.shape[1], 1)\n",
    "\n",
    "\n",
    "# produto cartesiano\n",
    "# Parâmetros para otimização\n",
    "neurons_options = [100]\n",
    "batch_size_options = [20]\n",
    "epochs_options = [20]\n",
    "\n",
    "results = []\n",
    "\n",
    "# 32x\n",
    "idx = 1\n",
    "while idx != 33:\n",
    "    for neurons in neurons_options:\n",
    "        for batch_size in batch_size_options:\n",
    "            for epochs in epochs_options:\n",
    "                    \n",
    "                print(f\"Combinação {idx}: neuronios={neurons}, batch_size={batch_size}, epochs_options={epochs}\")\n",
    "                    \n",
    "                # Construindo o modelo\n",
    "                modelo = Sequential()\n",
    "                modelo.add(LSTM(neurons, return_sequences=True, input_shape=(treinamento_x.shape[1], 1)))\n",
    "                modelo.add(LSTM(neurons // 2, return_sequences=False))\n",
    "                modelo.add(Dense((neurons // 2)//2))\n",
    "                modelo.add(Dense(1))\n",
    "\n",
    "                # Compilando o modelo\n",
    "                modelo.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "                    \n",
    "                # Treinando o modelo\n",
    "                modelo.fit(treinamento_x, treinamento_y, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "\n",
    "                # Criando dados de teste\n",
    "                dados_teste = dados_entre_0_e_1[tamanho_dados_treinamento - 60:, :]\n",
    "                teste_x = []\n",
    "                teste_y = cotacao[tamanho_dados_treinamento:, :]\n",
    "\n",
    "                for i in range(60, len(dados_teste)):\n",
    "                    teste_x.append(dados_teste[i - 60:i, 0])\n",
    "\n",
    "                teste_x = np.array(teste_x).reshape(len(teste_x), 60, 1)\n",
    "\n",
    "                # Pegando predições do modelo\n",
    "                predicoes = modelo.predict(teste_x)\n",
    "                predicoes = escalador.inverse_transform(predicoes)\n",
    "                    \n",
    "                # Criar df\n",
    "                df_previsao = pd.DataFrame({\"Date\": acao['Date'].iloc[tamanho_dados_treinamento:],\n",
    "                                                \"Price\": acao['Price'].iloc[tamanho_dados_treinamento:],\n",
    "                                                \"predicoes\": predicoes.reshape(len(predicoes))\n",
    "                                            })\n",
    "                    \n",
    "                df_previsao.set_index('Date', inplace=True)\n",
    "                    \n",
    "                df_previsao['Semana'] = ((df_previsao.index - df_previsao.index.min()).days // 7) + 1\n",
    "                    \n",
    "                    \n",
    "                    #========================== DIARIO ==========================\n",
    "                df_diario = df_previsao\n",
    "                # Cálculo da variação percentual entre os valores consecutivos\n",
    "                df_diario['Variação Real (%)'] = df_previsao['Price'].pct_change() * 100\n",
    "                df_diario['Variação Prevista (%)'] = df_previsao['predicoes'].pct_change() * 100\n",
    "\n",
    "                # Remover NaN (primeira linha não terá variação por não ter valor anterior)\n",
    "                df_diario = df_diario.dropna()\n",
    "\n",
    "                # Calcular se a direção do valor previsto foi igual ao real (1 = acertou | 0 = errou)\n",
    "                df_diario['direcao_correta'] = np.where(\n",
    "                    (df_diario['Variação Real (%)'] > 0) & (df_diario['Variação Prevista (%)'] > 0) |\n",
    "                    (df_diario['Variação Real (%)'] < 0) & (df_diario['Variação Prevista (%)'] < 0),\n",
    "                    1, 0\n",
    "                )\n",
    "\n",
    "                # Calcular a métrica de Erro de Direção (Directional Accuracy)\n",
    "                directional_accuracy_diario = df_diario['direcao_correta'].mean()\n",
    "                directional_accuracy_diario = round(directional_accuracy_diario * 100, 2)\n",
    "                    \n",
    "                #========================== SEMANAL ==========================\n",
    "                df_semana = df_previsao\n",
    "                # Agrupar por semana e calcular o preço médio semanal para real e previsões\n",
    "                df_semana = df_previsao.groupby('Semana').agg({\n",
    "                    'Price': 'mean',        # Preço real médio por semana\n",
    "                    'predicoes': 'mean'     # Previsão média por semana\n",
    "                })\n",
    "\n",
    "                # Calcular a variação percentual semanal para Price e Predicoes\n",
    "                df_semana['Variação Real (%)'] = df_semana['Price'].pct_change() * 100\n",
    "                df_semana['Variação Prevista (%)'] = df_semana['predicoes'].pct_change() * 100\n",
    "\n",
    "\n",
    "                # Remover NaN (primeira linha não terá variação por não ter valor anterior)\n",
    "                df_semana = df_semana.dropna()\n",
    "\n",
    "                # Calcular se a direção do valor previsto foi igual ao real (1 = acertou | 0 = errou)\n",
    "                df_semana['direcao_correta'] = np.where(\n",
    "                    (df_semana['Variação Real (%)'] > 0) & (df_semana['Variação Prevista (%)'] > 0) |\n",
    "                    (df_semana['Variação Real (%)'] < 0) & (df_semana['Variação Prevista (%)'] < 0),\n",
    "                    1, 0\n",
    "                )\n",
    "\n",
    "                # Calcular a métrica de Erro de Direção (Directional Accuracy)\n",
    "                directional_accuracy_semanal = df_semana['direcao_correta'].mean()\n",
    "                directional_accuracy_semanal = round(directional_accuracy_semanal * 100, 2)\n",
    "\n",
    "\n",
    "                # Avaliando o modelo\n",
    "                mae = mean_absolute_error(teste_y, predicoes)\n",
    "                mape = mean_absolute_percentage_error(teste_y, predicoes)\n",
    "                rmse = mean_squared_error(teste_y, predicoes, squared=False)\n",
    "                r2 = r2_score(teste_y, predicoes)\n",
    "\n",
    "                # Armazenando os resultados\n",
    "                results.append({\n",
    "                    'neurons': neurons,\n",
    "                    'batch_size': batch_size,\n",
    "                    'epochs': epochs,\n",
    "                    'MAE': mae,\n",
    "                    'MAPE': mape,\n",
    "                    'RMSE': rmse,\n",
    "                    'R2': r2,\n",
    "                    'directional_accuracy_diario': directional_accuracy_diario,\n",
    "                    'directional_accuracy_semanal': directional_accuracy_semanal\n",
    "                })\n",
    "                    \n",
    "                idx+=1\n",
    "\n",
    "# Convertendo resultados em DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Exibindo resultados\n",
    "print(results_df)\n",
    "\n",
    "# Gráfico do melhor modelo (opcional)\n",
    "best_model = results_df.loc[results_df['directional_accuracy_semanal'].idxmax()]\n",
    "\n",
    "print(f\"\\nMelhor Modelo: Neurônios={best_model['neurons']}, batch_size={best_model['batch_size']}, Epochs={best_model['epochs']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel(\"Resultado 100 20 20.xlsx\", engine=\"openpyxl\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
