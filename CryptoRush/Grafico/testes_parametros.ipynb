{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Diretório onde o script está localizado\n",
    "base_diretório = Path(os.getcwd())\n",
    "diretório_princapl = base_diretório.parent\n",
    "caminho = diretório_princapl / 'Bases' / 'BNB Historical Data.csv'\n",
    "\n",
    "# Ler o arquivo ano.txt e pegar o ano\n",
    "# with open(diretório_princapl/'data'/'ano.txt', 'r') as file:\n",
    "#     ano = int(file.read().strip()) \n",
    "ano = 2020\n",
    "\n",
    "# Ler arquivo da base\n",
    "acao = pd.read_csv(caminho)\n",
    "\n",
    "# Formatar data\n",
    "acao['Date'] = pd.to_datetime(acao['Date'])\n",
    "\n",
    "# Separar um df no qual vai conter apenas os dado para treinamento\n",
    "# Que é com base no ano escolhido pelo jogador\n",
    "df_treinamento = acao[acao['Date'].dt.year < ano]\n",
    "\n",
    "# Apenas cotação dos dados de treinamento \n",
    "cotacao_treinamento = df_treinamento['Price'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# Cotação dos dados da base toda\n",
    "cotacao = acao['Price'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# Armazenar tamanho dos dados de treinamento\n",
    "tamanho_dados_treinamento = int(len(cotacao_treinamento) * 1)\n",
    "\n",
    "# Escalar os dados entre 0 e 1\n",
    "escalador = MinMaxScaler(feature_range=(0, 1))\n",
    "dados_entre_0_e_1_treinamento = escalador.fit_transform(cotacao[0:tamanho_dados_treinamento, :])\n",
    "dados_entre_0_e_1_teste = escalador.transform(cotacao[tamanho_dados_treinamento:, :])\n",
    "\n",
    "dados_entre_0_e_1 = np.concatenate((dados_entre_0_e_1_treinamento, dados_entre_0_e_1_teste), axis=0)\n",
    "\n",
    "dados_para_treinamento = dados_entre_0_e_1[0:tamanho_dados_treinamento, :]\n",
    "treinamento_x, treinamento_y = [], []\n",
    "\n",
    "for i in range(60, len(dados_para_treinamento)):\n",
    "    treinamento_x.append(dados_para_treinamento[i - 60:i, 0])\n",
    "    treinamento_y.append(dados_para_treinamento[i, 0])\n",
    "\n",
    "# Transformando listas em arrays\n",
    "treinamento_x, treinamento_y = np.array(treinamento_x), np.array(treinamento_y)\n",
    "treinamento_x = treinamento_x.reshape(treinamento_x.shape[0], treinamento_x.shape[1], 1)\n",
    "\n",
    "\n",
    "# produto cartesiano\n",
    "# Parâmetros para otimização\n",
    "neurons_options = [50, 60, 70, 80, 90, 100]\n",
    "batch_size_options = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120]\n",
    "epochs_options = [10, 20]\n",
    "\n",
    "results = []\n",
    "\n",
    "# 30x\n",
    "idx = 1\n",
    "while idx < 31:\n",
    "    for neurons in neurons_options:\n",
    "        for batch_size in batch_size_options:\n",
    "            for epochs in epochs_options:\n",
    "                    \n",
    "                print(f\"Combinação {idx}: neuronios={neurons}, batch_size={batch_size}, epochs_options={epochs}\")\n",
    "                    \n",
    "                # Construindo o modelo\n",
    "                modelo = Sequential()\n",
    "                modelo.add(LSTM(neurons, return_sequences=True, input_shape=(treinamento_x.shape[1], 1)))\n",
    "                modelo.add(LSTM(neurons // 2, return_sequences=False))\n",
    "                modelo.add(Dense((neurons // 2)//2))\n",
    "                modelo.add(Dense(1))\n",
    "                # Compilando o modelo\n",
    "                modelo.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "                    \n",
    "                # Treinando o modelo\n",
    "                modelo.fit(treinamento_x, treinamento_y, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "                # Criando dados de teste\n",
    "                dados_teste = dados_entre_0_e_1[tamanho_dados_treinamento - 60:, :]\n",
    "                teste_x = []\n",
    "                teste_y = cotacao[tamanho_dados_treinamento:, :]\n",
    "                for i in range(60, len(dados_teste)):\n",
    "                    teste_x.append(dados_teste[i - 60:i, 0])\n",
    "                teste_x = np.array(teste_x).reshape(len(teste_x), 60, 1)\n",
    "                # Pegando predições do modelo\n",
    "                predicoes = modelo.predict(teste_x)\n",
    "                predicoes = escalador.inverse_transform(predicoes)\n",
    "                    \n",
    "                # Criar df\n",
    "                df_previsao = pd.DataFrame({\"Date\": acao['Date'].iloc[tamanho_dados_treinamento:],\n",
    "                                                \"Price\": acao['Price'].iloc[tamanho_dados_treinamento:],\n",
    "                                                \"predicoes\": predicoes.reshape(len(predicoes))\n",
    "                                            })\n",
    "                    \n",
    "                df_previsao.set_index('Date', inplace=True)\n",
    "                    \n",
    "                df_previsao['Semana'] = ((df_previsao.index - df_previsao.index.min()).days // 7) + 1\n",
    "                    \n",
    "                #========================== SEMANAL ==========================\n",
    "                df_semana = df_previsao\n",
    "                # Agrupar por semana e calcular o preço médio semanal para real e previsões\n",
    "                df_semana = df_previsao.groupby('Semana').agg({\n",
    "                    'Price': 'mean',        # Preço real médio por semana\n",
    "                    'predicoes': 'mean'     # Previsão média por semana\n",
    "                })\n",
    "                # Calcular a variação percentual semanal para Price e Predicoes\n",
    "                df_semana['Variação Real (%)'] = df_semana['Price'].pct_change() * 100\n",
    "                df_semana['Variação Prevista (%)'] = df_semana['predicoes'].pct_change() * 100\n",
    "                # Remover NaN (primeira linha não terá variação por não ter valor anterior)\n",
    "                df_semana = df_semana.dropna()\n",
    "                # Calcular se a direção do valor previsto foi igual ao real (1 = acertou | 0 = errou)\n",
    "                df_semana['direcao_correta'] = np.where(\n",
    "                    (df_semana['Variação Real (%)'] > 0) & (df_semana['Variação Prevista (%)'] > 0) |\n",
    "                    (df_semana['Variação Real (%)'] < 0) & (df_semana['Variação Prevista (%)'] < 0),\n",
    "                    1, 0\n",
    "                )\n",
    "                # Calcular a métrica de Erro de Direção (Directional Accuracy)\n",
    "                directional_accuracy_semanal = df_semana['direcao_correta'].mean()\n",
    "                directional_accuracy_semanal = round(directional_accuracy_semanal * 100, 2)\n",
    "                # Avaliando o modelo\n",
    "                mae = mean_absolute_error(teste_y, predicoes)\n",
    "                mape = mean_absolute_percentage_error(teste_y, predicoes)\n",
    "                rmse = mean_squared_error(teste_y, predicoes, squared=False)\n",
    "                # Armazenando os resultados\n",
    "                results.append({\n",
    "                    'neurons': neurons,\n",
    "                    'batch_size': batch_size,\n",
    "                    'epochs': epochs,\n",
    "                    'MAE': mae,\n",
    "                    'MAPE': mape,\n",
    "                    'RMSE': rmse,\n",
    "                    'directional_accuracy_semanal': directional_accuracy_semanal\n",
    "                })\n",
    "                    \n",
    "                idx+=1\n",
    "\n",
    "# Convertendo resultados em DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Exibindo resultados\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel(\"Resultados testes parametros/Bitcoin - Resultado geral.xlsx\", engine=\"openpyxl\", index=False)\n",
    "\n",
    "# Agrupar pelas combinações de parâmetros e calcular a média das métricas\n",
    "resultados_agrupados = results_df.groupby(['neurons', 'batch_size', 'epochs']).agg({\n",
    "    'MAE': 'mean',\n",
    "    'MAPE': 'mean',\n",
    "    'RMSE': 'mean',\n",
    "    'directional_accuracy_semanal': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Exibir os resultados agrupados\n",
    "print(resultados_agrupados)\n",
    "\n",
    "# Gráfico do melhor modelo (opcional)\n",
    "best_model = resultados_agrupados.loc[resultados_agrupados['directional_accuracy_semanal'].idxmax()]\n",
    "\n",
    "print(f\"\\nMelhor Modelo: Neurônios={best_model['neurons']}, batch_size={best_model['batch_size']}, Epochs={best_model['epochs']}\")\n",
    "\n",
    "resultados_agrupados.to_excel(\"Resultados testes parametros/BNB - resultado geral agrupado.xlsx\", engine=\"openpyxl\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
